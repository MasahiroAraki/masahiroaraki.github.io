<!DOCTYPE html>
<html lang="ja">

<head>
<meta charset="UTF-8">
<style type="text/css">

li {
  margin-bottom: 7px;
}

</style>

</head>
  <body>

    <div class="page-content">
      <div class="wrapper">
        <h1 id="section">論文</h1>
<ul>
  <li>東中 竜一郎，船越 孝太郎，荒木 雅弘，塚原 裕史，小林 優佳，水上 雅博: テキストチャットを用いた雑談対話コーパスの構築と対話破綻の分析, 自然言語処理, Vol.23, No. 1, pp.59-86, doi: http://doi.org/10.5715/jnlp.23.59, 2016.</li>
  <li>竹腰 大輔, 荒木 雅弘: コンテンツの情報構造を利用したマルチモーダル対話システム開発支援環境, 人工知能学会論文誌, Vol.30, No.1, pp.61-70, doi: http://doi.org/10.1527/tjsai.30.61, 2015.</li>
  <li>竹腰 大輔, 荒木 雅弘: データモデル定義に基づくマルチモーダル対話記述言語の設計と実装, 人工知能学会論文誌, Vol.28, No.3, pp.261-266, doi:http://doi.org/10.1527/tjsai.28.261, 2013.</li>
  <li>田中一晶, 尾関基行, 荒木雅弘, 岡夏樹: ロボットへの教示場面における「間」の重要性：ロボットの行動の遅れは学習効率を向上させ教えやすい印象を与える, 人工知能学会論文誌, Vol. 25, No. 6, pp.703-711, doi: http://doi.org/10.1527/tjsai.25.703, 2010.</li>
  <li>田中一晶, 左祥, 嵯峨野泰明, 荒木雅弘, 岡夏樹: No News規準が有効な条件：誘導教示の意味学習場面での実験的検討, 電子情報通信学会論文誌 A, Vol. J92-A, No.11, pp. 784-794, 2009.</li>
  <li>Masahiro Araki, Akiko Kouzawa and Kenji Tachibana: Proposal of a multimodal interaction description language for various interactive agents, IEICE transactions on information and systems, E88-D(11), pp.2469-2476, doi: http://doi.org/10.1093/ietisy/e88-d.11.2469, 2005.</li>
  <li>西本卓也, 高山元希, 櫻井晴章, 荒木雅弘: 音声インタフェースのための対話負荷測定法, 電子情報通信学会論文誌 D-II, Vol.J87-D-II, No.2, pp.513-520, 2004.</li>
  <li>立花健二, 荒木雅弘: 広報へのユニバーサル・ユビキタスアクセスの実現, 情報科学技術レターズ 3, pp.277-280, 2004.</li>
  <li>Yunbiao Xu, Masahiro Araki, Yasuhisa Niimi: A multilingual-supporting dialog system across multiple domains, Journal of Acoustical Science and Technology, Vol.24, No.6,pp.349-357, doi: http://doi.org/10.1250/ast.24.349, 2003.</li>
  <li>奥智岐, 西本卓也, 荒木雅弘, 新美康永: タスクに依存しない音声対話の制御方式, 電子情報通信学会論文誌 D-II, Vol.J86-D-II, No.5 pp.608-615, 2003.</li>
  <li>荒木雅弘: XMLスキーマ言語からの音声対話システムの自動生成．情報科学技術レターズ 1、pp.97-98, 2002.</li>
  <li>Yunbiao Xu, Xin Song, Masahiro Araki, Yasuhisa Niimi: A Chinese Speech Synthetic System Based On TD-PSOLA, Journal of Chinese Language Computing, Vol.11, No.1, pp.63-79, 2001.</li>
  <li>Yunbiao Xu, Masahiro Araki, Yasuhisa Niimi: A Chinese speech synthetic system based on monosyllable concatenation, Journal of Acoustical Science and Technology, Vol.23, No.3, pp.166-169, doi http://doi.org/10.1250/ast.23.166, 2002.</li>
  <li>西本卓也, 幸英浩, 川原毅彦, 荒木雅弘, 新美康永: 非同期型音声会議システムAVMの設計と評価; 電子情報通信学会論文誌 D-II, Vol.J83-D-II, No.11 pp.2490-2497, 2000.</li>
  <li>荒木雅弘, 堂下修司: 音声対話システムのための対話の認知プロセスモデル; 自然言語処理, Vol.6, No.4, pp.23-44, 1999.</li>
  <li>荒木雅弘, 熊谷智子, 伊藤敏彦, 石崎雅人: 発話単位タグ標準化案の作成; 人工知能学会論文誌, Vol.14, No.2, pp.251-260, 1999.</li>
  <li>駒谷和範, 荒木雅弘, 堂下修司: 対話コーパスにおける発話単位タグの一推定手法;人工知能学会論文誌, Vol.14, No.2, pp.273-281, 1999.</li>
  <li>荒木雅弘, 八木啓介, 杉谷公伸, 美濃導彦: 遠隔講義機器を統合的に管理するシステムの開発, 日本ディスタンスラーニング学会誌, Vol.1, pp.28-32, 1999.</li>
  <li>Taro Watanabe, Masahiro Araki, and Shuji Doshita. Evaluating dialogue strategies under communication errors using computer-to-computer simulation. IEICE transactions on information and systems, E81-D(9), pp.1025-1033, 1998.</li>
  <li>Masahiro Araki and Shuji Doshita. Cooperative spoken dialogue model using Bayesian network and event hierarchy. IEICE transactions on information and systems, E78-D(6), pp.629-635, 1995.</li>
</ul>

<h1 id="section-1">著書・解説</h1>
<ul>
  <li>荒木雅弘：フリーソフトでつくる音声認識システム - パターン認識・機械学習の初歩から対話システムまで - （第2版）, 森北出版, 2017</li>
  <li>荒木雅弘： イラストで学ぶ音声認識, 講談社 , 2015.</li>
  <li>荒木雅弘： 総合プロセーシス学の諸相(森本 一成、神田 和幸(編著)), 第1章, pp.14-24, ユニオンプレス, 2014.</li>
  <li>荒木雅弘：フリーソフトではじめる機械学習入門, 森北出版, 2014.</li>
  <li>荒木雅弘：音声対話システム構築のための統計的アプローチ, 日本音響学会誌 68(2), pp.98-103, 2012.</li>
  <li>荒木雅弘：フリーソフトで学ぶセマンティックWebとインタラクション, 森北出版, 2010.</li>
  <li>荒木雅弘、西本卓也：基礎講座 音響・音声インタフェース 第2回 音声対話システムの開発方法論とプラットフォーム,  ヒューマンインタフェース学会誌 Vol.12 No.2, pp.51-54, May 2010.</li>
  <li>荒木雅弘：フリーソフトでつくる音声認識システム - パターン認識・機械学習の初歩から対話システムまで -, 森北出版, 2007</li>
  <li>河原達也、荒木雅弘：音声対話システム、オーム社, 2006. (2017年8月現在 3刷)</li>
  <li>Ramon Delgado and Masahiro Araki. Spoken, Multilingual and Multimodal Dialogue Systems: Development And Assessment, Wiley, 2005.</li>
  <li>Masahiro Araki, Masato Ishizaki, Shu Nakazato and Yoichi Yamashita. Discourse Annotation Schemes for Japanese Task-Oriented Dialogues, in S. Nakagawa, M. Okada and T. Kawahara (eds.) “Spoken Language Systems”, IOS Press, pp.332-342, 2005.</li>
  <li>荒木雅弘: ボイスウェブの可能性-VoiceXML概説-,情報処理学会誌, Vol.44, No. 10, pp.1044-1051, 2003.</li>
  <li>荒木雅弘: コンピュータネットワーク(池田克夫編著), 第5章, オーム社, 2001. (2017年11月現在 15刷)</li>
  <li>堂下修司, 荒木雅弘: 音声による人間と機械の対話(堂下他編著), 5編4章, オーム社, 1998</li>
  <li>M. Araki and S. Doshita: Automatic evaluation environment for spoken dialogue systems; In E.Mayer, M.Mast, and S.LuperFoy, editors, Dialogue Processing in Spoken Language Systems, pp.183-194. Springer, 1997</li>
  <li>西田豊明, 荒木雅弘: 認知科学ハンドブック 空間的知識の表現と利用(分担), 共立出版, pp.293-301,1992</li>
</ul>

<h1 id="section-2">国際会議等</h1>
<ul>
<li> Hiroshi Nakatani, Shigenori Nishiumi, Takahiro Maeda and Masahiro Araki. KIT Dialogue System for NTCIR-13 STC-2 Task, Proceedings of the 13th NTCIR Conference on Evaluation of Information Access Technologies, pp.257-264, Dec. 7 2017. <a href="http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings13/pdf/ntcir/11-NTCIR13-STC-NakataniH.pdf">[PDF]</a></li></li>
<li>Sayaka Tomimasu and Masahiro Araki: Assessment of users' interests in multimodal dialog based on exchange unit. In Proceedings of the Workshop on Multimodal Analyses enabling Artificial Agents in Human-Machine Interaction (MA3HMI '16). ACM, New York, NY, USA, pp.33-37, 2016. doi: https://doi.org/10.1145/3011263.3011269 </li>
  <li>Hideaki Mori and Masahiro Araki: Selection method of an appropriate response in chat-oriented dialogue systems. In Proc. SIGDIAL 2016, pp. 228-231, 2016. <a href="http://www.sigdial.org/workshops/conference17/proceedings/pdf/SIGDIAL29.pdf">[PDF]</a></li>
  <li>Sota Matsumoto and Masahiro Araki: Scoring of response based on suitability of dialogue-act and content similarity, In Proc. NTCIR-12, 2016. <a href="http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings12/pdf/ntcir/STC/09-NTCIR12-STC-MatsumotoS.pdf">[PDF]</a></li>
  <li>Tomo Horii, Hideaki Mori and Masahiro Araki: A breakdown detector in chat-oriented dialogue, In Proc. IWSDS, 2016.</li>
  <li>Hideaki Mori, Atsushi Yasuda and Masahiro Araki: An evaluation method of system response in chat-oriented dialogue system, In Proc. IWSDS, 2016.</li>
  <li>Ryuichiro Higashinaka, Masahiro Mizukami, Kotaro Funakoshi, Masahiro Araki, Hiroshi Tsukahara and Yuka Kobayashi: Fatal or not? Finding errors that lead to dialogue breakdowns in chat-oriented dialogue systems, In Proc. EMNLP 2015, pp.2243-2248, 2015.</li>
  <li>Ryuichiro Higashinaka, Kotaro Funakoshi, Masahiro Mizukami, Hiroshi Tsukahara, Yuka Kobayashi and Masahiro Araki: Analyzing dialogue breakdowns in chat-oriented dialogue systems, In Proc. ERRARE 2015, 2015.</li>
  <li>Ryuichiro Higashinaka, Kotaro Funakoshi, Masahiro Araki, Hiroshi Tsukahara, Yuka Kobayashi and Masahiro Mizukami: Towards Taxonomy of Errors in Chat-oriented Dialogue Systems, In Proc. SIGDIAL 2015, pp.87-95, 2015.</li>
  <li>Weiwei Du, Motoyuki Ozeki, Hiroki Nomiya, Kazuyoshi Murata, Masahiro Araki: Pair programming for enhancing communication in the fundamental C language
exercise, In Proc. COMPSAC 2015, pp. 664-665, DOI: 10.1109/COMPSAC.2015.67, 2015.</li>
  <li>Daisuke Takegoshi and Masahiro Araki: Development Environment for Multimodal Interactive System based on Ontological Knowledge,  In Proc. IIAI AAI 2014, pp.785-788, DOI 10.1109/IIAI-AAI.2014.158, 2014.</li>
  <li>Masahiro Araki: Representation method for significant pauses in a multimodal motion learning system, In Proc. IIAI AAI 2013, pp.361-364, DOI 10.1109/IIAI-AAI.2013.33, 2013.</li>
  <li>Masahiro Araki: Multimodal Motion Learning System for Traditional Arts, In Proc. AHFE2012, pp.5274-5281, 2012.</li>
  <li>Masahiro Araki and Daisuke Takegoshi: A Rapid Development Framework for Multilingual Spoken Dialogue Systems, In Proc. COMPSAC 2012, pp.195-202, 2012.</li>
  <li>Masahiro Araki: Rapid Development Process of Spoken Dialogue Systems using Collaboratively Constructed Semantic Resources, In Proc. SIGDial 2012, pp.70-73, 2012.</li>
  <li>Masahiro Araki and Daisuke Takegoshi: Framework for the Development of Spoken Dialogue System based on Collaboratively Constructed Semantic Resources, In Proc. NAACL-HLT Workshop, pp.25-28, 2012.</li>
  <li>Masahiro Araki and Yuko Mizukami: Development of a Data-driven Framework for Multimodal Interactive Systems, In Proceedings of IWSDS 2011, pp.91-101, 2011.</li>
  <li>Masahiro Araki, Kana Shibahara and Yuko Mizukami: Spoken dialogue system for learning Braille, In Proceedings of IEEE COMPSAC 2011.pp.152 - 156, 2011.</li>
  <li>M. Araki and Y. Funakura: Impact of Semantic Web on the Development of Spoken Dialogue Systems, In Proceedings of the Second international conference on Spoken dialogue systems for ambient environments (IWSDS 2010),  pp.144-149, 2010.</li>
  <li>M. Araki and T. Hattori: Proposal of a Practical Spoken Dialogue System Development Method: Data-management Centered Approach,   In W. Minker et al. (eds) Spoken Dialogue Systems Technology and Design, Springer, pp.187-211, 2010.</li>
  <li>M. Araki: Filling the gap between a large-scale database and multimodal interactions, In Proc. Third International Conference on Large-Scale Knowledge Resources, LKR 2008, pp.179-185, LNCS Vol. 4938, Springer, 2008.</li>
  <li>M. Araki: Proposal of a Markup Language for Multimodal Semantic Interaction, In Proc. Workshop on Multimodal Interfaces in Semantic Interaction, pp.58-62, 2007.</li>
  <li>Masahiro Araki, Tsuneo Nitta, Kouichi Katsurada, Takuya Nishimoto, Tetsuo Amakasu and Shinnichi Kawamoto: Proposal of a Hierarchical Architecture for Multimodal Interactive Systems. W3C MMI workshop. 2007</li>
  <li>M. Araki and K. Tachibana: Multimodal Dialog Description Language for Rapid System Development, In Proc. 7th SIGdial Workshop on Discourse and Dialogue, pp.109-116, 2006.</li>
  <li>T. Nitta, S. Sagayama, Y. Yamashita, T. Kawahara, S. Morishima, S. Nakamura, A. Yamada, K. Ito, M. Kai, A. Li, M. Mimura, K. Hirose, T. Kobayashi, K. Tokuda, N. Minematsu, Y. Den, T. Utsuro, T. Yotsukura, H. Shimodaira, M. Araki, T. Nishimoto, N. Kawaguchi, H. Banno, K. Katsurada: Activities of Interactive Speech Technology Consortium (ISTC) Targeting Open Software Development for MMI Systems, In Proc. 13th IEEE International Workshop on Robot and Human Interactive Communication, 2004.</li>
  <li>西本卓也, 荒木雅弘，伊藤克亘，宇津呂武仁, 甲斐充彦，河口信夫，河原達也，桂田浩一，小林隆夫，嵯峨山茂樹，下平博，伝康晴，徳田恵一，中村 哲，新田恒雄，坂野秀樹，広瀬啓吉，峯松信明, 三村正人，森島繁生, 山下洋一，山田篤，四倉達夫，李晃伸: Galatea:音声対話擬人化エージェント開発キット, インタラクション2004, pp.27-28, 2004.</li>
  <li>M. Araki, H. Ohmiya and S. Kida: Input Prediction Method of Speech Front End Processor Using Prosodic Information, In Proc. of Int’l Conf: Speech Prosody 2004, 2004.</li>
  <li>Y. Xu, F. Di, M. Araki and Y. Niimi: Methods to Improve Its Portability of A Spoken Dialog System Both on Task Domains and Languages, Proc. of Eurospeech 2003.</li>
  <li>M. Araki, A, Kaga and T. Nishimoto: Comparison of “Go back” implementations in VoiceXML, In Proc. of ISCA workshop on ERROR HANDLING IN SPOKEN DIALOGUE SYSTEMS, 2003.</li>
  <li>M. Araki: Spoken Dialogue Agent Architecture for Web Service Mediator, In Proc. of First INTERNATIONAL WORKSHOP ON Language Understanding and Agents for Real World Interaction, 2003.</li>
  <li>M. Araki, J. Kurahashi and T. Matsumoto: EXTREME EXPERIMENT (XE) METHOD FOR DEVELOPING MIXED INITIATIVE DIALOGUE SYSTEMS, Proc. ISCA &amp; IEEE Workshop on Spontaneous Speech Processing and Recognition, 2003. PDF</li>
  <li>M. Araki, OWL-based Frame Description for Spoken Dialog Systems, Proc. International Semantic Web Foundations and Application Technology (SWFAT) workshop, 2003.</li>
  <li>M. Araki, K. Ueda, M. Akita, T. Nishimoto, and Y. Niimi: Proposal of a Multimodal Dialogue Description Language, In Proc. of PRICAI02, 2002.</li>
  <li>T. Nishimoto, M. Araki, and Y. Niimi: RadioDoc: A Voice-Accessible Document System, In Proc. of ICSLP2002, 2002.</li>
  <li>M. Araki, T. Ono, K. Ueda, T. Nishimoto, and Y. Niimi: Dialogue pattern generation algorithm in database search task; In Proc. NAACL workshop on adaptation in dialogue systems, 2001.</li>
  <li>M. Araki, T. Ono, T. Nishimoto, and Y. Niimi: VoiceXML generator of slot-filling transaction dialogue; In Proc. 5th workshop on semantics and pragmatics in dialogue, pp. 251-258, 2001.</li>
  <li>M. Araki, T. Ono, K. Ueda, T. Nishimoto, and Y. Niimi: An automatic dialogue system generator from the internet information contents; In Proc. of Eurospeech 2001, pp. 1743-1746, 2001.</li>
  <li>Y. Niimi, T. Oku, T. Nishimoto, and M. Araki: A rule based approach to extraction of topics and dialog acts in a spoken dialog system; In Proc. of Eurospeech 2001, pp. 2185-2188, 2001.</li>
  <li>Y. Xu, M. Araki, and Y. Niimi: A multilingual-supporting dialog system using a common dialog controller; In Proc. of Eurospeech 2001, pp. 1283-1286, 2001.</li>
  <li>M. Araki, Y. Kimura, T. Nishimoto, and Y. Niimi: Development of a machine learnable discourse tagging tool; In Proc. of 2nd SIGDIAL Workshop on Discourse and Dialogue, pp. 20-25, 2001.</li>
  <li>M. Araki, K. Ueda, T. Nishimoto, and Y. Niimi: Dialogue scenario generation from xml-based database; In Proc. of 1st NLP and XML Workshop, pp. 9-14, 2001.</li>
  <li>Y. Xu, M. Araki, and Y. Niimi: A chinese speech synthetic system based on TD-PSOLA; In Proc. of Int’l Conf. on Chinese Computing, pp. 171-175, 2001.</li>
  <li>T. NISHIMOTO, M. ARAKI, Y. NIIMI: The Practical Side of Teaching the Elderly Visually Impaired User to Use the E-Mail; Proceedings of the UAHCI 2001 Conference (Universal Access in Human-Computer Interaction), Vol.3, pp.963-967, 2001.</li>
  <li>M. Araki, T. Nishimoto, and Y. Niimi: Dialogue system generator from the world wide web; In Memories of KIT, Vol. 49, pp. 57-66, 2001</li>
  <li>M. Araki, K. Ueda, T. Nishimoto, and Y. Niimi: A semantic tagging tool for spoken dialogue corpus; In Proc. 6th Int’l Conf. on Spoken Language Processing, Vol. 4, pp. 720 - 723, 2000</li>
  <li>Y. Niimi, T. Oku, T. Nishimoto, and M. Araki: A Task-Independent Dialogue Controller Based On The Extended Frame-Driven Method; In Proc. 6th Int’l Conf. on Spoken Language Processing, Vol. 1, pp. 114 - 117, 2000.</li>
  <li>M.Araki, S.Nakagawa, J.Nomura, and S.Doshita: Incremental utterance understanding using phrase based plan recognition, In Proc. 18th Int’l Conf. on Computer Processing of Oriental Languages, 1999.</li>
  <li>M. Araki, K. Komatani, T. Hirata and S. Doshita: A Dialogue Library for Task-oriented Spoken Dialogue Systems, Proc. IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems,pp.1-7, 1999.</li>
  <li>A. Ichikawa, M. Araki, Y. Horiuchi, M.Ishizaki, S. Itabashi, T. Itoh, H. Kashioka, K. Kato, H. Kikuchi, H. Koiso, T. Kumagai, A. Kurematsu, K. Maekawa, S. Nakazato, M. Tamoto, S. Tutiya, Y. Yamashita, and T. Yoshimura: Evaluation of Annotation Schemes for Japanese Discourse, Proc. of ACL ‘99 Workshop on Towards Standards and Tools for Discourse Tagging, pp.26-34, 1999.</li>
  <li>M.Araki and S.Doshita: A robust dialogue model for spoken dialogue processing, In Proc. 5th Int’l Conf. on Spoken Language Processing, pages1171 - 1174, 1998.</li>
  <li>A.Ichikawa, M.Araki, M.Ishizaki, S.Itabashi, T.Itoh, H.Kashioka, K.Kato, H.Kikuchi, T.Kumagai, A.Kurematsu, H.Koiso, M.Tamoto, S.Tutiya, S.Nakazato, Y.Horiuchi, K.Maekawa, Y.Yamashita, and T.Yoshimura: Standardising annotation schemes for japanese discourse; In Proc. 1st Int’l Conf. on Language Resourse and Evaluation, 1998.</li>
  <li>M.Araki, T.Watanabe, and S.Doshita: Evaluating dialogue strategies under various communication errors, In Proc. of IJCAI Workshop on Collaboration, Cooperation and Conflict in Dialogue Systems, pp. 13-18, 1997.</li>
  <li>M. Araki, T. Kawahara, T. Nishida and S. Doshita: Automatic evaluation environment for spoken dialogue systems, Proc. of ECAI Workshop on Dialogue Processing in Spoken Language Systems, pp. 8 - 12, Budapest Hungary, 1996.</li>
  <li>T.Kawahara, M.Araki, and S.Doshita: Comparison of parsing and spotting approaches for spoken dialogue understanding, Proc. ESCA workshop on Spoken Dialogue Systems, pp. 21 - 24, Vigso Denmark, 1995.</li>
  <li>M. Araki, T. Kawahara and S. Doshita: Cooperative spoken dialogue model using Bayesian network and event hierarchy, Proc. ESCA workshop on Spoken Dialogue Systems, pp. 177 - 180, Vigso Denmark, 1995.</li>
  <li>M. Araki, T. Watanabe, F. Quimbo and S. Doshita:  A cooperative man-machine dialogue model for problem solving, Proc. Int’l Conf. on Spoken Language Processing, pp. 883 - 886, Yokohama, 1994.</li>
  <li>T. Kawahara, M. Araki and S. Doshita: Heuristic search integrating syntactic, semantic and dialog-level constraints, Proc. IEEE Int’l Conf. Acoust., Speech &amp; Signal Processing, Vol. 2, pp. 25 - 28, Adelaide Australia, 1994.</li>
  <li>T. Kawahara, M. Araki and S. Doshita: Reducing syntactic perplexity of user utterances with automaton dialogue model, Proc. Int’l Sympo. on Spoken Dialogue, pp. 65 - 68, Tokyo, 1993.</li>
  <li>M. Araki, T. Kawahara and S. Doshita: A keyword-driven parser for spontaneous speech understanding, Proc. Int’l Sympo. on Spoken Dialogue, pp. 113 - 116, Tokyo, 1993.</li>
  <li>M. Araki, T. Kawahara, T. Nishida and S. Doshita: Keyword-driven speech parser using dialog-level knowledge, Proc. Pacific Rim Int’l Conf. on Artificial Intelligence, pp. 1025 - 1029, Seoul Korea, 1992.</li>
</ul>

<h1 id="section-3">口頭発表</h1>
<ul>
  <li> 荒木雅弘, 冨増紗也華, 中野幹生, 駒谷和範, 岡田将吾, 藤江真也, 杉山弘晃: マルチモーダル対話データの収集と興味判定アノテーションの分析, SIG-SLUD-B508-05, pp.20-pp.25, 2017.
<a href="https://jsai.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=8920&file_id=1&file_no=1">[AI書庫]</a></li>
  <li> 荒木雅弘: 機械学習を学ぶための対話型チュータリングシステムの開発, 2017年度人工知能学会全国大会論文集, 1B3-5, 2017. 
<a href="https://kaigi.org/jsai/webprogram/2017/pdf/1166.pdf">[PDF]</a></li>
  <li> 林卓矢, 荒木雅弘: 常識から外れた雑談応答の検出, 言語処理学会第23回年次大会, P15-3, 2017. 
<a href="http://www.anlp.jp/proceedings/annual_meeting/2017/pdf_dir/P15-3.pdf">[PDF]</a></li>
  <li> 堀井朋, 森秀晃, 林卓矢, 荒木雅弘: 破綻類型情報に基づく雑談対話破綻検出.SIG-SLUD,B5(02),pp.75-pp.80, 2016. 
<a href="https://jsai.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=1302&file_id=1&file_no=1">[AI書庫]</a></li>
  <li> 森秀晃, 荒木雅弘: 拡張性・多様性を備えた雑談対話システムのための開発フレームワーク. SIG-SLUD,B5(02),pp.144-pp.145, 2016.
<a href="https://jsai.ixsq.nii.ac.jp/ej/?action=repository_uri&item_id=1318&file_id=1&file_no=1">[AI書庫]</a></li>
  <li>冨増紗也華、荒木雅弘: 雑談対話におけるマルチモーダル情報からの興味の有無の判定, 2016年度人工知能学会全国大会論文集, 2O4-OS-23a-1, 2016.
<a href="https://kaigi.org/jsai/webprogram/2016/pdf/824.pdf">[PDF]</a></li>
  <li>堀井朋, 荒木雅弘: 類型毎の破綻検出器におけるエラー分析, 言語処理学会第22回年次大会, E2-2, 2016.</li>
  <li>堀井朋, 荒木雅弘: 類型毎の検出手法の組合せによる雑談発話破綻検出の検討, SIG-SLUD-075-08, pp.33-36, 2015.</li>
  <li>辻勇一朗, 岡夏樹, 尾関基行, 荒木雅弘, 深田智, 長井隆行, 中村友昭, 大森隆司: 発話における応答部・主導部の推定とそれらを構成する単語の推定, 2015年度人工知能学会全国大会論文集, 2D3-OS-12b-5, 2015.</li>
  <li>中野哲寛, 荒木雅弘: 雑談対話システムにおける単語分散表現を用いた話題展開手法, 言語処理学会第21回年次大会, B1-2, 2015.</li>
  <li>大月仁志, 荒木雅弘, 渡辺太郎: Word Alignment Model with Longer Contexts, 言語処理学会第21回年次大会, A7-5, 2015.</li>
  <li>東中竜一郎, 船越孝太郎, 荒木雅弘, 塚原裕史, 小林優佳, 水上雅博: Project Next NLP 対話タスク：雑談対話データの収集と対話破綻アノテーションおよびその類型化, 言語処理学会第21回年次大会ワークショップ, 2015.</li>
  <li>安田篤史，荒木雅弘：相談対話における顔文字による発話感情の記録,日本音響学会秋期研究発表会, 音講論, 2-P-17, 2013.</li>
  <li>井手麻友美, 荒木雅弘: マルチモーダル対話記述における関数による解釈表現の検討, 2013年度人工知能学会全国大会論文集, 1K3-OS-17a-3, 2013.</li>
  <li>安田篤史，荒木雅弘：音声認識結果への顔文字の付与,日本音響学会春期研究発表会, 音講論, 3-P-13a, 2013.</li>
  <li>西牟田勇哉，荒木雅弘: セマンティックWebのための音声質問文の検索クエリへの変換, 第75回情報処理学会全国大会, 4N-6, 2013.</li>
  <li>小澤克貴, 荒木雅弘: マルチドメイン構造を用いたセマンティックWeb検索対話システムの提案,情報処理学会研究報告, 2013-SLP-95(2), 2013.</li>
  <li>竹腰大輔, 荒木雅弘: データモデル定義に基づくマルチモーダル対話記述言語の設計と実装, 2012年度人工知能学会全国大会論文集, 1O2-OS-18-6, 2012.</li>
  <li>荒木雅弘: オブジェクト指向的な対話システム開発言語の提案, SIG-SLUD-B102-04, 2011.</li>
  <li>荒木雅弘: Railsフレームワークを用いたマルチモーダル対話システム, SIG-SLUD-B002-05, 2010.</li>
  <li>荒木雅弘: 機械学習による対話制御 －その必要性と可能性－, 音講論, 2010年3月, (招待講演).</li>
  <li>古林沙夜香，荒木雅弘: マルチモーダル対話システムのためのユーザ／デバイスモデルの構築, SIG-SLUD-A903-12, 2010.</li>
  <li>舩倉悠，春木智行，荒井亮太，荒木雅弘: セマンティック・ボイスサーチにおける検索表現の生成, SIG-SLUD-A903-13, 2010.</li>
  <li>柴原花奈, 荒木雅弘:音声対話を用いた点字学習システムの開発, 信学技報, vol. 109, no. 259, SP2009-54, pp. 31-36, 2009.</li>
  <li>荒木雅弘, 西本卓也, 桂田浩一, 新田 恒雄: 階層的MMIアーキテクチャに基づくプラットフォーム実装方法の検討, 情報処理学会研究報告, 2009-SLP-78-5, 2009.</li>
  <li>中川 祐一, 荒木 雅弘: 様々なデバイスに適応するマルチモーダル出力分化手法, 人工知能学会研究会資料, SIG-SLUD-A803-04, 2009.</li>
  <li>服部 貴志, 荒木 雅弘: コンテンツのメタデータを利用した質問応答手法の提案, 人工知能学会研究会資料, SIG-SLUD-A803-05, 2009.</li>
  <li>寺村 真加寿, 荒木 雅弘: オントロジーを利用した音声入力質問文の解析, 人工知能学会研究会資料, SIG-SLUD-A702-2, 2007.</li>
  <li>守時 理裕, 荒木 雅弘: 音声対話システムにおけるユーザ適応技術の統合手法の提案, SIG-SLUD-A702-3, 2007.</li>
  <li>新田 恒雄, 桂田 浩一, 荒木 雅弘, 西本 卓也, 甘粕 哲郎, 川本 真一: マルチモーダル対話システムのための階層的アーキテクチャの提案, 情報処理学会研究報告, 2007-SLP-68-2, 2007.</li>
  <li>守時 理裕, 荒木 雅弘: 音声対話システムにおけるユーザ適応技術の統合手法の提案, 言語処理学会全国大会, PD3-5, 2007.</li>
  <li>寺村真加寿, 荒木雅弘: オントロジーを用いた音声入力質問文の解析手法の提案, 言語処理学会全国大会, PD3-6, 2007.</li>
  <li>南 芳憲, 荒木雅弘：観賞タスクにおける言語情報および非言語情報のユーザモデルへの利用, ヒューマンインタフェース学会 第9回ノンバーバルインタフェース専門研究会, pp.39-42, 2005.</li>
  <li>紅澤 明子, 立花 健二, 荒木 雅弘: TIP階層モデルに基づくMMI記述言語, 人工知能学会研究会資料, SIG-SLUD-A404-2, 2005.</li>
  <li>青木 俊樹, 大迎 純也, 荒木 雅弘: 多言語音声対話システムにおける応答生成, 人工知能学会研究会資料, SIG-SLUD-A404-1, 2005.</li>
  <li>荒木雅弘, 角田眞美, 南芳憲: パーソナルロボットとの感動共有インタラクション, 人工知能学会研究会資料, SIG-SLUD-A403-4, 2005.</li>
  <li>西本 卓也，荒木 雅弘，伊藤 克亘，宇津呂 武仁，甲斐 充彦，河口 信夫，河原 達也，桂田 浩一，小林 隆 夫，嵯峨山 茂樹，下平 博，伝康晴，徳田 恵一，中村 哲，新田 恒雄，坂野 秀樹，広瀬 啓吉，峯松 信明，三村 正人，森島 繁生，山下 洋一，山田 篤，四倉 達夫，李 晃伸: Galatea: 音声対話擬人化エージェント開発キット, In Proc. Workshop on Interactive Systems and Software, 2004.</li>
  <li>大迎純也, 荒木雅弘: 多言語音声ポータルシステムの構築, 情報処理学会研究報告, 2004-SLP-54-55, 2004.</li>
  <li>大宮広義, 荒木雅弘: エージェントとの対話によってユーザの操作を支援するVoiceWebシステム, 情報処理学会研究報告, 2004-SLP-54-47, 2004.</li>
  <li>荒木雅弘: 多言語音声対話システムアーキテクチャの比較検討, 情報処理学会研究報告, 2004-SLP-53-4, 2004.</li>
  <li>荒木雅弘: 音声対話エージェント実用化への課題, 情報処理学会研究報告, 2004-SLP-52-10, 2004.</li>
  <li>立花健二, 荒木雅弘: ユーザの嗜好を学習するエージェントを用いた広報配信システム, 人工知能学会研究会資料, SIG-SLUD-A401-1, 2004.</li>
  <li>荒木雅弘, 大宮広義: 韻律情報を利用した予測型音声入力システム, 言語処理学会第10回年次大会, P4-6, 2004.</li>
  <li>荒木雅弘: VoiceXMLとUMLを用いたオブジェクト指向的対話システム開発手法の提案, FIT2003論文集, F-028, 2003.</li>
  <li>荒木雅弘, 秋田祥史: フレーム駆動によるマルチモーダル対話制御方式, 言語処理学会第9回年次大会併設ワークショップ, 2003.</li>
  <li>重野真也, 井上武史, 荒木雅弘: XMLスキーマ言語と対話例を用いた音声対話システムの自動構築手法, 人工知能学会研究会資料, SIG-SLUD-A203-P18, 2003.</li>
  <li>住吉悠希, 荒木雅弘, 西本卓也: ラジオ番組収録のための音声インタフェースの設計と評価, 人工知能学会研究会資料, SIG-SLUD-A203-P19, 2003.</li>
  <li>西本卓也, 高山元希, 荒木雅弘: 音声インタフェースにおける認知的負荷測定法とその評価, 情報処理学会研究報告, 2003-SLP-45-5, 2003.</li>
  <li>岐津三泰, 西本卓也, 荒木雅弘: 擬人化エージェントのためのVoiceXML処理系の開発, 人工知能学会研究会資料, SIG-SLUD-A201-1, 2002.</li>
  <li>伊藤秀樹, 重野真也, 西本卓也, 荒木雅弘, 新美康永: 対話における雰囲気の分析, 情報処理学会研究報告, 2002-SLP-40-18, 2002.</li>
  <li>木下育子, 西本卓也, 荒木雅弘, 新美康永: 隠れマルコフモデルを用いたアクセント型の認識, 電子情報通信学会技術研究報告, SP2001-140, pp.37-42, 2002.</li>
  <li>高山元希，西本卓也，荒木雅弘，新美康永: 電話音声応答システムにおける効果音の役割, 電子情報通信学会技術研究報告, SP2001-132, pp.55-62, 2002.</li>
  <li>荒木雅弘: 音声対話システムとVoiceXML, 人工知能学会研究会資料, SIG-SLUD-A103-7, 2001.</li>
  <li>大谷和寛, 荒木雅弘, 西本卓也, 新美康永: 対話例からの混合主導型音声対話システムの構築, 人工知能学会研究会資料, SIG-SLUD-A103-4, 2001.</li>
  <li>西本卓也, 櫻井晴章, 荒木雅弘, 新美康永: ディクテーション作業における楽しさの分析, 人工知能学会研究会資料, SIG-SLUD-A103-1, 2001.</li>
  <li>植田喜代志, 秋田祥史, 荒木雅弘, 西本卓也, 新美康永: VoiceXMLのマルチモーダル化の検討, 情報処理学会研究報告, 2001-SLP-38-7, 2001.</li>
  <li>荒木雅弘, 小野佑, 植田喜代志, 西本卓也, 新美康永: データベースからの検索対話パターンの生成; 言語処理学会全国大会論文集, 2001.</li>
  <li>奥智岐, 西本卓也, 荒木雅弘, 新美康永: 対話コーパスからの対話制御情報の取得; 情報処理学会研究報告, 2001-SLP-37-2, 2001.</li>
  <li>木村幸彦, 新美康永, 荒木雅弘, 西本卓也: 機械学習を用いた談話タグ推定手法; 人工知能学会研究会資料, SIG-SLUD-0003-8, 2001.</li>
  <li>Y. Xu, T. Nishimoto, M. Araki, and Y. Niimi: A chinese speech synthetic system based on TD-PSOLA; 日本音響学会講演論文集, pp. 1-2-17, 2001.</li>
  <li>笠松正紀，西本卓也，荒木雅弘，新美康永: 適応素片を用いた感情音声の合成, 電子情報通信学会技術研究報告, SP2000-165, pp.41-46, 2001.</li>
  <li>植田喜代志, 荒木雅弘, 西本卓也, 新美康永: 対話システムのための意味解析ツールの開発; 2000年度人工知能学会全国大会論文集, pp. 420-421, 2000</li>
  <li>奥智岐, 西本卓也, 荒木雅弘, 新美康永: タスクに依存しないフレーム駆動型対話制御方式; 情報処理学会研究報告, 2000-SLP-32-11, 2000.</li>
  <li>荒木雅弘, 小野佑, 植田喜代志, 西本卓也, 新美康永: XML-VoiceXML変換ツールの開発; 情報処理学会研究報告, 2000-SLP-34-33, 2000.</li>
  <li>西本卓也, 幸英浩, 川原毅彦, 荒木雅弘, 新美康永: 非同期型バーチャル会議システム AVM; 電子情報通信学会総合大会, SD-4-9, pp.279-280, 2000.</li>
  <li>西本卓也, 荒木雅弘, 新美康永: 視覚障害者のためのタイピング練習ソフト「打ち込み君」の改良; 電子情報通信学会技術研究報告,WIT00-21, pp.55-59, 2000.</li>
  <li>西本卓也, 住吉悠希, 荒木雅弘, 新美康永: 視覚障害者のための電子メール環境における操作性の検討; ヒューマンインタフェース学会研究報告集, Vol.2 No.5, pp.33-38, 2000.</li>
  <li>荒木 雅弘, 駒谷 和範, 平田 大志, 堂下 修司: 音声対話システム構築のための対話ライブラリ, 人工知能学会研究会資料，SIG-SLUD-9901-1，pp.1-6，京都, 1999.</li>
  <li>荒木雅弘: 京都大学における遠隔講義システムの概要, 平成10年度情報処理教育研究集会, 福岡, 1998.</li>
  <li>荒木雅弘, 八木啓介, 美濃導彦: SCS学内配信機能を持つ遠隔講義システムの概要, 日本教育工学会大会講演論文集 14, 209-212, 北海道, 1998.</li>
  <li>駒谷和範, 荒木雅弘, 堂下修司: 発語内行為タグの推定法とそのタグ付与支援ツールへの組み込み, 人工知能学会研究会資料, SIG-SLUD-9801-5, 京都, 1998.</li>
  <li>今井裕之, 荒木雅弘, 堂下修司: 遠隔講義・会議での利用を目的とした音声によるAV制御システムの作成, 1998年度人工知能学会全国大会講演論文集, pp.189-192, 東京, 1998.</li>
  <li>荒木雅弘, 八木啓介、美濃導彦: ATMネットワークを用いた遠隔講義映像の伝送, インターネット技術第163委員会(ITRC) 第3回総会・研究会, 滋賀, 1998.</li>
  <li>駒谷和範, 荒木雅弘, 堂下修司: 対話コーパスにおける表層情報を利用した発語内行為タグの推定, 言語処理学会第４回年次大会講演論文集，pp.406-409，福岡, 1998.</li>
  <li>市川熹, 荒木雅弘 他: 談話タグ標準化の現状, 人工知能学会研究会資料SIG-SLUD-9703-7, 東京, 1998.</li>
  <li>岩井康浩, 荒木雅弘, 堂下修司: 対話コーパスに対する意味・談話タグの推定手法, 人工知能学会研究会資料SIG-SLUD-9703-5, 東京, 1998.</li>
  <li>野村淳一,佐々木哲之,荒木雅弘, 堂下修司: マルチモーダル作図システムにおける文脈知識を利用した発話理解, 人工知能学会研究会資料SIG-SLUD-9703-1, 東京, 1998.</li>
  <li>荒木雅弘: 京都大学における遠隔講義システムの構想と課題, インターネット技術第163委員会(ITRC) 第2回総会・研究会, pp. 151 - 158, 和歌山, 1997.</li>
  <li>荒木雅弘, 市川熹 他: 談話タグワーキンググループ活動報告, 人工知能学会研究会資料, SIG-SLUD-9701-6, 京都, 1997.</li>
  <li>野村淳一, 荒木雅弘, 堂下修司: 音声・マウス・キーボードによるマルチモーダル作図システム, 1997年度人工知能学会全国大会講演論文集, pp.388-391, 東京, 1997.</li>
  <li>池田徹志, 佐々木哲之, 荒木雅弘, 堂下修司: 音声・ジェスチャ・図像を統合したマルチモーダル情報の理解, 人工知能学会研究会資料, SIG-SLUD-9603-3, 東京, 1997.</li>
  <li>渡辺太郎, 荒木雅弘, 堂下修司: 対話システムにおける知識の相違および認識誤りの解消, 情報処理学会研究報告, 96-SLP-14-7, 東京, 1996.</li>
  <li>東郁雄, 荒木雅弘, 堂下修司: 対話データベースへの意味情報の付与, 第53回情報処理学会全国大会講演論文集, 7L-6, pp.115-116, 大阪, 1996.</li>
  <li>池田徹志, 荒木雅弘, 堂下修司: 図像情報を利用した講演調音声のディクテーション, 第53回情報処理学会全国大会講演論文集, 7N-6, pp.357-358, 大阪, 1996.</li>
  <li>野村淳一, 荒木雅弘, 堂下修司: 句単位でのプラン認識による漸進的発話理解システムの実 現, 1996年度人工知能学会全国大会講演論文集, pp.415-418, 東京, 1996.</li>
  <li>渡辺太郎, 荒木雅弘, 堂下修司: 目的指向型対話における対話交渉モデル, 言語処理学会第2回年次大会講演論文集, pp.349-352, 東京, 1996.</li>
  <li>荒木雅弘, 東郁雄, 田中吾一, 堂下修司: 模擬対話データのデータベース化と事例ベース意味解析の適用, 情報処理学会研究報告, 95-SLP-8-5, 東京, 1995.</li>
  <li>荒木雅弘, 堂下修司: 対話の自由度と発話の自由度に基づく音声対話システムの設計法, 人工知能学会研究会資料SIG-SLUD-9502, 京都, 1995.</li>
  <li>東郁雄, 荒木雅弘, 堂下修司: 音声対話データの収録と意味的情報の統計的分析, 1995年度人工知能学会全国大会講演論文集, pp.541-544, 東京, 1995.</li>
  <li>荒木雅弘, 堂下修司: 協調的対話におけるシステムの理解度に応じた発話生成, 第50回情報処理学会全国大会講演論文集, 4R-1, pp.85-86, 東京, 1995.</li>
  <li>池田徹志, 荒木雅弘, 堂下修司: Bayesian networkを用いた意図理解, 言語処理学会第1回年次大会講演論文集, pp.69-72, 東京, 1995.</li>
  <li>Jonathan Shih, 荒木雅弘, 堂下修司: マルチエージェント分散対話スケジューリングシステムにおけるマシン対マシン通信プロトコルの設計, 第49回情報処理学会全国大会講演論文集, 4N-5, pp.289-290, 北海道, 1994.</li>
  <li>中川真也, 荒木雅弘, 堂下修司: 文頭からの意味的区切りの抽出による意味表現の生成, 第49回情報処理学会全国大会講演論文集, 4G-2, pp.157-158, 北海道, 1994.</li>
  <li>荒木 雅弘, 堂下 修司: 対話事例ベースによる発話内容の推定および未知語の解析, 第49回情報処理学会全国大会講演論文集, Vol.3, 4G-1, pp.155-156, 北海道, 1994.</li>
  <li>F. Quimbo, M. Araki, and S. Doshita: Topic identification and prediction based on the domain plan and the discourse structure, 1994年度人工知能学会全国大会講演論文集, pp.591-594, 東京, 1994.</li>
  <li>荒木雅弘, 渡辺太郎, 堂下修司: 対話による協調的問題解決のモデリング, 1994年度人工知能学会全国大会講演論文集, pp.587-590, 東京, 1994.</li>
  <li>中川真也, 荒木雅弘, 堂下修司: 断片的発話からの増進的な意味解析, 第48回情報処理学会全国大会講演論文集, 7R-3, pp.223-224, 千葉, 1994.</li>
  <li>Jonathan Shih, 荒木雅弘, 堂下修司: Proposal of a negotiation protocol for multi-user scheduling system, 第48回情報処理学会全国大会講演論文集, volume 3, pp.233-234, 千葉, 1994.</li>
  <li>額賀信尾, 荒木雅弘, 河原達也, 堂下修司: 概念階層構造を持つネットワークを用いた漸進的音声言語理解, 信学技報, SP93-126, pp.63-70, 京都, 1994.</li>
  <li>河原達也, 荒木雅弘, 好田健祐, 額賀信尾, 堂下修司: 対話レベルの知識を利用した音声認識の高精度化, 電子情報通信学会大会講演論文集, SA-6-3, 秋季, 東京, 1993.</li>
  <li>河原達也, 荒木雅弘, 堂下修司: 対話の状態遷移モデルを用いた次発話構文の予測, 日本音響学会研究発表会講演論文集, 1-8-12, 秋季, 山梨, 1993.</li>
  <li>額賀信尾, 荒木雅弘, 河原達也, 堂下修司: 音声対話理解のための意味ネットワーク上のMessage Passingに基づく部分文解析, 人工知能学会全国大会, p.441-444, 東京, 1993.</li>
  <li>額賀信尾, 荒木雅弘, 河原達也, 堂下修司: 意味ネットワーク上のmessage passingに基づく部分文解析, 人工知能学会研究会資料, SIG-SLUD-9301-3, pp. 19 - 26, 筑波, 1993.</li>
  <li>荒木雅弘, 宗続敏彦, 河原達也, 堂下修司: 意味主導型パーサによる自由発話の解析, 情報処理学会第46回全国大会, 1E-4, 東京, 1993.</li>
  <li>河原達也, 荒木雅弘, 宗続敏彦, 堂下修司: left-to-rightパーザとkeyword-drivenパーザの比較と自由発話音声理解の試み, 日本音響学会研究発表会講演論文集, 3-4-9, 春季, 東京, 1993.</li>
  <li>河原達也, 荒木雅弘: Spontaneous speechの理解のための処理モデル, Spontaneous Speechの分析・理解・生成に関するシンポジウム, SPREC93-1, pp.49-53, 東京, 1993.</li>
  <li>宗續敏彦, 河原達也, 荒木雅弘, 堂下修司: 自由発話理解のためのキーワードスポッティング手法, 信学技報, SP92-116, pp.7-14, 京都, 1993.</li>
  <li>額賀信尾, 荒木雅弘, 河原達也, 堂下修司: 会話音声認識における探索へのネットワーク表現による意味制約の利用, 第45回情報処理学会全国大会講演論文集(3), pp.77-78, 徳島, 1992.</li>
  <li>荒木雅弘, 西田豊明, 堂下修司: 多レベルの知識を利用した意味主導型音声入力解析手法, 人工知能学会全国大会, 15-9, p.559-562, 東京, 1992.</li>
  <li>荒木雅弘, 西田豊明, 堂下修司: キーワード抽出に基づく意味解析による音声対話システム, 第44回情報処理学会全国大会講演論文集(2), 6N-4, pp.151-152, 神奈川, 1992.</li>
  <li>河原達也, 荒木雅弘: left-to-right A* 探索と keyword-driven解釈の比較, 連続音声認識シンポジウム, SPREC91-2, pp.29-32, 東京, 1992.</li>
  <li>荒木雅弘, 河原達也, 西田豊明, 堂下修司: キーワード抽出に基づく意味解析による音声対話システム , 信学技報SP91-94, pp. 25 - 32, 東京, 1991.</li>
  <li>荒木雅弘, 石橋広吏, 西田豊明, 堂下修司: Dempster-Shaferの理論に基づく音韻情報と構文情報の統合による音声入力文の解析, 人工知能学会全国大会, 15-2, pp.591-594, 東京, 1991.</li>
  <li>荒木雅弘, 斉藤隆, 佐藤研治, 西田豊明, 堂下修司: 対話の構造と単語の概念を利用した発話の理解, 第42回情報処理学会全国大会講演論文集(3), 4C-1, pp.61-62, 東京, 1991.</li>
  <li>荒木雅弘, 西田豊明, 堂下修司: 概念情報を利用した会話文の構造解析, 人工知能学会全国大会, 13-4, p.393-396, 東京, 1990.</li>
</ul>


      </div>
    </div>

  </body>

</html>
